# Compilers

Stuff related to compilers

## Directory structure

- **llvm**: Building a foundation to integrate llvm with flex and bison

- **other_compiler_stuff**: Some old works and experiences in compilers

## Notes

### LLVM and Python Past, Present, Future

[Talk link](https://www.youtube.com/watch?v=C57HjehxBRc)

- Numba and llvmlite are making decent progress. llvmlite offers python bindings to LLVM backend, specificially the JIT execution engine.

- CPython execution workflow:

    - Tokens: read a file and tokenizes it

    - Concrete syntax tree or parsing (overlaps a lot)

    - Abstract syntax tree

    - Bytecode (and control flow graph like structures) code objects

    - Execution on CPython's virtual machine. 


- CPython virtual machine:

    - Bytecode code objects are to be executed here

    - Sequence of `opcode, opargs`

![Sample python code](./images/3.png)

![Disassembly](./images/4.png)

IR of loading `x` and `4` to compare.

- Dynamic nature of CPython:

    - No static type checks possible

    - No level of trust; users can change even builtins

    - Everything is mutable

    - **Global Interpreter Lock**: a simple lock that forces only a single thread to take over the Python interpreter at any given time. The reason for this was **reference count** based garbage collection. Basically, each object has a count counting the number of references to that object; when this count reaches 0, the garbage collector frees this object. However, this is prone to **race conditions** in multi-thread architectures. First solution is to have **multiple locks** but that is recipe for **deadlock**. Hence, GIL is the solution: make only one thread take over the python interpreter at any given time. 

**Why past attempts failed?**

- Unladen shallow

    - Initially sponsored by Google by then they lost interest

    - Started as a fork of CPython and planned to eventually merge

    - GIL problem implied they fell short of their targetted speedup

    - Static linking: really nice to not make people unnecessarily build LLVM from source

    - Upto **8x memory usage** (the native code, the AST, the bytecode, everything is in memory) and overhead of LLVM libraries. LLVM is a heavy project after all

    - Optimzation performer structures whose job was to optimise bytecode actually ended up taking more memory than required

    - **Increase in startup time**: the decision to statically link LLVM to python binaries implies increased startup times, overhead of C runtime routines

    - **Increase in binary size**: caused due to static linking

    - Back then (2009), LLVM was not good and had some JIT issues.

    - **At least back then**, LLVM isn't suited to dynamic languages without collecting data at runtime

- pyLLVM

    - especially suited to python subset consisting mainly of numerical routines, machine learning, and returned numerical computations

### Flang : The Fortran frontend of LLVM 

This technical talk introduces the new Fortran fronted of LLVM.

[Talk link](https://www.youtube.com/watch?v=XiYAIzGCadc)

- Fortran is very popular in high performance computing and finds usage in the real world as in numerical simulation, weather forecasting.

- With flang, LLVM now has a frontend for Fortran. The old flang became the frontend for many corporate compilers, including AMD AOCC.

#### Stages of the flang compiler

- Preprocessing: normalises the source and outputs a cooked character stream

- Provenance: Maps the cooked character stream to the original source. Very useful in case of errors.

- Parsing: Recursive descent parsing. Uses the idea of parser combinators. 

![Example of F18 parsing](./images/1.png)

Note how the standard grammar rule is implemented. Note the optional portion of the grammar; contrast this with your actual grammar structure wherein you have different rules for different structures. Nothing is optional there.

- Semantic analysis: 
    
    - Check the grammar rules

    - Jump label resolution

    - Name resolution

    - Removes ambiguity in the parse tree

    - Constant expression evaluation

    - Expression and Statement semantic checks

    - Finally the module files are generated

Fortran dumps the modules as the fortran source itself. Have an example:

![How are modules treated?](./images/2.png)

- Optimizer: Uses MLIR (a framework for generating IR). Several optimisations happen before the Fortran IR is converted in LLVM IR. 
